{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7939dd42-c26f-4d35-af0f-cfff2a2c821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation methods \n",
    "    #  Hold-out\n",
    "    #  K-folds\n",
    "    #  Leave-one-out\n",
    "# links followed\n",
    "#https://www.cs.cmu.edu/~schneide/tut5/node42.html#:~:text=Leave%2Done%2Dout%20cross%20validation,is%20made%20for%20that%20point.\n",
    "#https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446296f-e400-4a94-a51f-596098253866",
   "metadata": {},
   "source": [
    "K-Fold "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a79d5e-ab03-46a2-a2d0-5a0ad14ae27d",
   "metadata": {},
   "source": [
    "k-Fold Cross-Validation: The dataset is divided into k folds (in this case, 5 folds). \n",
    "Each fold serves as a test set exactly once, and the rest of the data is used for training. \n",
    "The KFold function from scikit-learn is used to create the fold indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0483aa33-2133-4b68-b155-f8c8c8a25bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SerialNo</th>\n",
       "      <th>GREScore</th>\n",
       "      <th>TOEFLScore</th>\n",
       "      <th>UniversityRating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>ChanceofAdmit</th>\n",
       "      <th>PassOrFail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SerialNo  GREScore  TOEFLScore  UniversityRating  SOP  LOR   CGPA  \\\n",
       "0         1       337         118                 4  4.5   4.5  9.65   \n",
       "1         2       324         107                 4  4.0   4.5  8.87   \n",
       "2         3       316         104                 3  3.0   3.5  8.00   \n",
       "3         4       322         110                 3  3.5   2.5  8.67   \n",
       "4         5       314         103                 2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  ChanceofAdmit   PassOrFail  \n",
       "0         1            0.92           0  \n",
       "1         1            0.76           0  \n",
       "2         1            0.72           0  \n",
       "3         1            0.80           0  \n",
       "4         0            0.65           1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "# Dataset Loading \n",
    "file_path = '/home/ex5/Desktop/AdmissionChangedDataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db6262d9-0a39-4b2c-af89-e25c8ba9c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (Accuracy): [0.91 0.86 0.87 0.87 0.9 ]\n",
      "Mean Accuracy: 0.882\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Support Vector Machine (SVM) classifier with a linear kernel\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop(columns=[\"PassOrFail\"])\n",
    "y = df[\"PassOrFail\"]\n",
    "\n",
    "# Set the number of folds for k-fold cross-validation\n",
    "num_folds = 5\n",
    "\n",
    "# Initialize a KFold object for splitting the dataset into k folds\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform k-fold cross-validation using the SVM classifier\n",
    "cross_val_results = cross_val_score(svm_classifier, X, y, cv=kf)\n",
    "\n",
    "# Print the cross-validation results\n",
    "print(f'Cross-Validation Results (Accuracy): {cross_val_results}')\n",
    "print(f'Mean Accuracy: {cross_val_results.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a675c-c055-49be-b03a-9b5f4dc7f52e",
   "metadata": {},
   "source": [
    "Summary\n",
    "The cross-validation results indicate an average accuracy of 88.2% across five folds. \n",
    "This suggests that the model performs well in predicting whether a student passes or \n",
    "fails admission based on given features.\n",
    "\n",
    "Interpretation:\n",
    "The model demonstrates strong predictive performance, with an average accuracy of 88.2%. \n",
    "This implies that it can effectively differentiate between students likely to pass or fail \n",
    "admission based on their GRE scores, TOEFL scores, university ratings, statements of purpose, \n",
    "letters of recommendation, CGPA, and research experience.\n",
    "\n",
    "Justification:\n",
    "The high mean accuracy of 88.2% suggests that the model generalizes well to unseen data, \n",
    "indicating robustness and reliability. This is crucial for admission prediction systems, \n",
    "ensuring fair evaluation of candidates based on diverse academic and personal factors. \n",
    "Such accuracy reinforces confidence in using the model for admission decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de15dd-a65e-4751-b515-70c962505e41",
   "metadata": {},
   "source": [
    "======================================================================================================================================================================================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55803a1c-7a7f-47c6-8972-ada205ea8b04",
   "metadata": {},
   "source": [
    "Leave-One-Out Cross-Validation (LOOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668bb57c-a583-4ad8-be82-b9da1d934a22",
   "metadata": {},
   "source": [
    "the Leave-One-Out Cross-Validation (LOOCV) method is implicitly utilized through the cross_val_score function when the \n",
    "number of folds (cv) is set to the length of the dataset (len(X)). LOOCV essentially creates as many folds as there \n",
    "are data points in the dataset, where each data point serves as a separate test set, and the remaining data points \n",
    "are used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb604e9-ab9e-4847-add1-15038fbf6f56",
   "metadata": {},
   "source": [
    "Leave-One-Out Cross-Validation (LOOCV) is applied by setting the cv parameter of the cross_val_score function to None. \n",
    "When cv is set to None, scikit-learn automatically performs LOOCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2c97378-d6b9-4f2d-8403-147d747b2cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Results (Accuracy): [1. 1. 1. 1. 1.]\n",
      "Mean Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ex5/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ex5/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ex5/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ex5/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/ex5/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X1 = df.drop(columns=[\"PassOrFail\"])\n",
    "X1 = df.drop(columns=[\"SerialNo\"])\n",
    "y1 = df[\"PassOrFail\"]\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "model1 = LogisticRegression()\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "cross_val_results = cross_val_score(model1, X1, y1, cv=None)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f'Cross-Validation Results (Accuracy): {cross_val_results}')\n",
    "print(f'Mean Accuracy: {cross_val_results.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59207e3b-6e00-471e-b998-7cd47e598c94",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "The cross-validation results indicate perfect accuracy of 100% across all folds. \n",
    "This suggests that the model predicts whether a student passes or fails admission \n",
    "with absolute certainty based on the given features.\n",
    "\n",
    "Justification:\n",
    "The perfect mean accuracy of 100% demonstrates the model's i.e. Logistic Regression\n",
    "exceptional performance in accurately classifying students as pass or fail \n",
    "based on their GRE scores, TOEFL scores, university ratings, statements of purpose, \n",
    "letters of recommendation, CGPA, and research experience. This flawless accuracy implies \n",
    "that the model effectively captures the underlying patterns in the data and makes highly \n",
    "accurate predictions without errors. Such remarkable performance underscores the robustness \n",
    "and reliability of the model, making it a valuable tool for admission decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51411ff-8d1b-42b3-bb8c-ad4688500790",
   "metadata": {},
   "source": [
    "=========================================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea71cc-59e8-4302-939a-145991ca5694",
   "metadata": {},
   "source": [
    "Hold-Out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d9b59-bb70-486a-a662-fcaf438485e2",
   "metadata": {},
   "source": [
    "In this code for the holdout method, cross-validation is not explicitly applied. \n",
    "The holdout method is a simple technique where the dataset is split into two subsets: a training set \n",
    "and a testing set. The model is trained on the training set and evaluated on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73c32953-539f-419e-b1ee-329cfbfaa5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holdout Method Results (Accuracy): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ex5/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "# Initialize Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "# Train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "# Predict the target variable on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Print the accuracy\n",
    "print(f'Holdout Method Results (Accuracy): {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8356c-e33e-4465-a194-04d357f64b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
